{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "versión de tensorflow: 1.4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(\"versión de tensorflow:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de ejemplos de entrenamiento: 55000\n",
      "Número de ejemplos de validación: 5000\n",
      "Número de ejemplos de prueba: 10000\n",
      "Tamaño de cada dígito: 784\n",
      "Tamaño de cada etiqueta: 10\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "import time\n",
    "\n",
    "### Los Ejemplos de entrenamiento están en: \n",
    "# mnist.train.images\n",
    "print(\"Número de ejemplos de entrenamiento:\", mnist.train.images.shape[0])\n",
    "\n",
    "### El conjunto de validacion es: \n",
    "# mnist.validation\n",
    "print(\"Número de ejemplos de validación:\", mnist.validation.images.shape[0])\n",
    "\n",
    "\n",
    "### El conjunto de prueba es: \n",
    "# mnist.test\n",
    "print(\"Número de ejemplos de prueba:\", mnist.test.images.shape[0])\n",
    "\n",
    "\n",
    "### Cada dígito es un vector de dimensión 784 .\n",
    "print(\"Tamaño de cada dígito:\", mnist.train.images.shape[1])\n",
    "\n",
    "\n",
    "### Las etiquetas se encuentran en: \n",
    "# mnist.train.labels\n",
    "# mnist.validation.labels\n",
    "# mnist.test.labels\n",
    "\n",
    "print(\"Tamaño de cada etiqueta:\", mnist.train.labels.shape[1])\n",
    "#Cada etiqueta es un one-hot-vector,ie. un vector con un solo uno, las demás entradas son cero\n",
    "#[1,0,0,0,0,0,0,0,0,0]  representa el número 0\n",
    "#[0,1,0,0,0,0,0,0,0,0]  representa el número 1\n",
    "#   .\n",
    "#   .\n",
    "#   .\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Muestra Dígito "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cada dígito se almacena como un vector de 784 dimensiones. Para visualizarlo, primero lo redimensionamos a una imagen de 28x28.\n",
    "def muestra_digito(x):\n",
    "    \"\"\"\n",
    "        x: vector \n",
    "            784 dimensiones\n",
    "        Muestra el vector como una imágen de 28x28\n",
    "    \"\"\"\n",
    "    plt.axis('off')\n",
    "    plt.imshow(x.reshape((28,28)), cmap=plt.cm.gray)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def vis_imagen(i, conjunto=\"train\"):\n",
    "    \"\"\"\n",
    "        i indice del conjunto especificado\n",
    "        conjunto: cadena\n",
    "            Cualquiera: train, validation, test\n",
    "            \n",
    "        Muestra el dígito en el indice i  y su etiqueta\n",
    "    \"\"\"\n",
    "    if(conjunto==\"train\"): \n",
    "        muestra_digito(mnist.train.images[i,])\n",
    "        label = np.argwhere(mnist.train.labels[i])[0][0]\n",
    "    elif(conjunto==\"test\"): \n",
    "        muestra_digito(mnist.test.images[i,])\n",
    "        label = np.argwhere(mnist.test.labels[i])[0][0]\n",
    "    else:\n",
    "        muestra_digito(mnist.validation.images[i,])\n",
    "        label = np.argwhere(mnist.validation.labels[i])[0][0]\n",
    "    print(\"Etiqueta \" + str(label))\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d583c0edd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiqueta 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d583ba9390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiqueta 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d583ba4f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiqueta 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d583b7d748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiqueta 4\n"
     ]
    }
   ],
   "source": [
    "vis_imagen(0, conjunto=\"train\")\n",
    "vis_imagen(132, conjunto=\"validation\")\n",
    "vis_imagen(32, conjunto=\"test\")\n",
    "vis_imagen(50000, conjunto=\"train\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RED NEURONAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placeholders para los datos de entrenamiento\n",
    "### En ellos se pasaran despues los datos de entrenamiento (x,y)\n",
    "### x imagen, y etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784]) \n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables del modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Capa 1\n",
    "W_1 = tf.Variable(tf.truncated_normal(shape = [784,512], stddev=0.2))\n",
    "b_1 = tf.Variable(tf.zeros([512]))\n",
    "\n",
    "### Capa 2 de salida\n",
    "W_2 = tf.Variable(tf.truncated_normal(shape = [512,10], stddev=0.2))\n",
    "b_2 = tf.Variable(tf.zeros([10]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arquitectura de la red neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN(x):\n",
    "    \"\"\"\n",
    "        x: matriz\n",
    "            su forma  debe ser (m, 784)\n",
    "            \n",
    "        regresa la activación de la capa de salida\n",
    "        matriz de (m, 10)\n",
    "    \"\"\"\n",
    "    # Capa Escondida 1. \n",
    "    z_1 = tf.matmul(x,W_1) + b_1 ### Combinación lineal\n",
    "    a_1  = tf.nn.relu(z_1)     ### Activación (función no lineal)\n",
    "    \n",
    "    # Capa 2. Está es la capa de salida\n",
    "    z_2 = tf.matmul(a_1,W_2) + b_2 ### Combinación lineal\n",
    "    \n",
    "    return z_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función de costo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = NN(x)\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = y_, labels = y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = tf.nn.softmax(y_) # predicciones en el conjunto de entrenamiento\n",
    "### Nota: la función softmax calcula la probabilidad de cada etiqueta del 0 al 9.\n",
    "#Para obtener la predicción necesitamos usar las función tf.argmax(y_,1) o su versión en python np.argmax(y_,1)\n",
    "#Así se elige el dígito más probable para la imágen\n",
    "#Esto lo hace la función precision\n",
    "\n",
    "y_valid = NN(mnist.validation.images)\n",
    "valid_pred = tf.nn.softmax(y_valid) # predicciones en el conjunto de validación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizador "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sesión e inicializacion de varables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session() #Crea una sessión\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Precisión\n",
    "def precision(predicciones, etiquetas):\n",
    "    return (100.0 * np.sum(np.argmax(predicciones, 1) == np.argmax(etiquetas, 1))\n",
    "          / predicciones.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento:\n",
      "Costo del minibatch hasta el paso 0: 7.695889\n",
      "Precisión en el conjunto de entrenamiento: 4.0%\n",
      "Precision en el conjunto de validación: 17.6%\n",
      "\n",
      "\n",
      "Costo del minibatch hasta el paso 500: 0.097601\n",
      "Precisión en el conjunto de entrenamiento: 98.0%\n",
      "Precision en el conjunto de validación: 96.0%\n",
      "\n",
      "\n",
      "Costo del minibatch hasta el paso 1000: 0.079301\n",
      "Precisión en el conjunto de entrenamiento: 97.0%\n",
      "Precision en el conjunto de validación: 96.9%\n",
      "\n",
      "\n",
      "Costo del minibatch hasta el paso 1500: 0.028340\n",
      "Precisión en el conjunto de entrenamiento: 100.0%\n",
      "Precision en el conjunto de validación: 97.4%\n",
      "\n",
      "\n",
      "Costo del minibatch hasta el paso 2000: 0.035874\n",
      "Precisión en el conjunto de entrenamiento: 98.0%\n",
      "Precision en el conjunto de validación: 97.4%\n",
      "\n",
      "\n",
      "Costo del minibatch hasta el paso 2500: 0.038116\n",
      "Precisión en el conjunto de entrenamiento: 99.0%\n",
      "Precision en el conjunto de validación: 97.4%\n",
      "\n",
      "\n",
      "Costo del minibatch hasta el paso 3000: 0.014822\n",
      "Precisión en el conjunto de entrenamiento: 100.0%\n",
      "Precision en el conjunto de validación: 97.6%\n",
      "\n",
      "\n",
      "Costo del minibatch hasta el paso 3500: 0.042495\n",
      "Precisión en el conjunto de entrenamiento: 99.0%\n",
      "Precision en el conjunto de validación: 97.6%\n",
      "\n",
      "\n",
      "Costo del minibatch hasta el paso 4000: 0.013436\n",
      "Precisión en el conjunto de entrenamiento: 100.0%\n",
      "Precision en el conjunto de validación: 97.9%\n",
      "\n",
      "\n",
      "Costo del minibatch hasta el paso 4500: 0.012864\n",
      "Precisión en el conjunto de entrenamiento: 100.0%\n",
      "Precision en el conjunto de validación: 98.0%\n",
      "\n",
      "\n",
      "Wall time: 12.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "pasos = 5000\n",
    "\n",
    "print(\"Entrenamiento:\")\n",
    "for i in range(pasos):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    _,costo,predicciones =  sess.run([opt, cross_entropy, train_pred],  feed_dict={x: batch[0], y: batch[1]})\n",
    "    \n",
    "    if (i % 500 == 0):\n",
    "        print(\"Costo del minibatch hasta el paso %d: %f\" % (i, costo))\n",
    "        print(\"Precisión en el conjunto de entrenamiento: %.1f%%\" % precision(predicciones, batch[1]))\n",
    "        print(\"Precision en el conjunto de validación: %.1f%%\" % precision(\n",
    "        valid_pred.eval(session=sess), mnist.validation.labels))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión en el conjunto de PRUEBA: 97.6%\n"
     ]
    }
   ],
   "source": [
    "y_test = NN(mnist.test.images)\n",
    "test_prediction = tf.nn.softmax(y_test)\n",
    "print(\"Precisión en el conjunto de PRUEBA: %.1f%%\" % precision(test_prediction.eval(session = sess), mnist.test.labels))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAABQdJREFUeJzt3C+L1FsAx+Gdy30JKwgWg0E22WRRk2Aw2ixishsMJsE3oF3FYLCIwSRs0XdgtAj+Abe4Bi2yIL/7Cvaw7oyzc+fzPPXr7J7y4YTj7Gyapg2g55/jPgBwPMQPUeKHKPFDlPghSvwQJX6IEj9EiR+i/l3mL5vNZv47Ifxl0zTNDvPv3PwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1Hih6h/j/sA/F1nzpwZ7k+fPh3u9+/fH+47Ozt/fCZWg5sfosQPUeKHKPFDlPghSvwQJX6I8s6/5u7duzfcL168ONxv3Lgx3N++fTvc9/f3hzvHx80PUeKHKPFDlPghSvwQJX6I8tS35s6dOzfcp2ka7tvb28N9a2truL979264c3zc/BAlfogSP0SJH6LED1HihyjxQ5R3/rjv378P92fPng33L1++LPI4LJGbH6LED1HihyjxQ5T4IUr8ECV+iPLOH7e7uzvcf/z4Mdz39vYWeRyWyM0PUeKHKPFDlPghSvwQJX6IEj9Eeedfc48fPx7uDx48GO4nT55c5HFYIW5+iBI/RIkfosQPUeKHKPFDlPghyjv/mtvc3Jzr81+/fl3QSVg1bn6IEj9EiR+ixA9R4oco8UOUp741t7+/P9fnf/36taCTsGrc/BAlfogSP0SJH6LED1HihyjxQ5R3/jU37zv/8+fPF3QSVo2bH6LED1HihyjxQ5T4IUr8ECV+iPLOvwbOnj174Hb9+vW5fvb58+eH+87Ozlw/n+Pj5oco8UOU+CFK/BAlfogSP0SJH6K886+B9+/fH7hdvnx5+Nnd3d3hvrW1Ndy98/9/ufkhSvwQJX6IEj9EiR+ixA9R4oco7/xrbm9vb7i/fv16SSdh1bj5IUr8ECV+iBI/RIkfosQPUbNpmpb3y2az5f0yDuXVq1fD/cSJE8N9e3t7kcdhAaZpmh3m37n5IUr8ECV+iBI/RIkfosQPUeKHKF/pjfv9+/dwP3Xq1HDf3Nwc7t++ffvjM7Ecbn6IEj9EiR+ixA9R4oco8UOU+CHK9/njLly4MNzfvHkz3O/cuTPcHz58+KdHYk6+zw8MiR+ixA9R4oco8UOU+CFK/BDlnZ+hz58/D/dPnz4N90uXLi3yOByCd35gSPwQJX6IEj9EiR+ixA9R/nQ3Qy9fvhzut27dGu6nT58+cPv48eMRTsSiuPkhSvwQJX6IEj9EiR+ixA9R4ocoX+ll6MqVK8P9xYsXw/3JkycHbrdv3z7SmRjzlV5gSPwQJX6IEj9EiR+ixA9R4oco7/zM5e7du8P95s2bB25Xr14dfvbDhw9HOVKed35gSPwQJX6IEj9EiR+ixA9R4oco7/zMZfR3+Tc2NjYePXp04Pbz58/hZ69du3aUI+V55weGxA9R4oco8UOU+CFK/BAlfojyzg9rxjs/MCR+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1Hih6il/uluYHW4+SFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oeo/wA8prM0gyJkFwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d58f0190b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiqueta 1\n"
     ]
    }
   ],
   "source": [
    "indice = 251\n",
    "p = tf.argmax(NN(mnist.test.images[indice:indice+1]).eval(session = sess),1)\n",
    "print(\"Predicción:\", sess.run(p)[0])\n",
    "vis_imagen(indice, conjunto=\"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
